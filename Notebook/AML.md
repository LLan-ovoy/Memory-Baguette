# Introduction

* Trends in ML: 

  * Deep Learning
    * text generation
    * Translation
    * Picture/music recognition

  * Natural Language Processing

    * BERT
    * unsupervised pretrainnng:
      * training models on tasks generated by natural text
      * with it can traning models with fewer labelled examples.
    * When using, need to easily finetune a little

  * > What is Transfer Learning?

    > Improvement of learning on a new task by trasfering the knowledge from a related task that have already been learned

    * recycling
    * good for image and NLP

  * Appiled ML:

    * Deep nerual nets:
      * convolutional nets for image
      * RNNs, BERT/Transformer for NLP
    * ensembled model add 2-5% in performance, but also rather comlex and not worth it in practice.

* ML in industry
  * feature engineering
  
  * recommender system
  
  * ***Models, but not just building mdels - selecting and framing a problem***
    
    * *start with a business problem*
    
      * *establish a baseline*
      * *check your assumption*
      * *Select model/learning technique*
      * *Select feature*
      * *Measure/evaluate, experiment*
      * *stability scalability robustness*
    
    * *break down the problem*
    
    * *understand the impact*
    
    * *Find the right data*
    
    * *select an objective function*
    
    * *build models*
    
    * *measure and evaluate*
    
      * *definiting the right metrics*
      * *offline evaluation*
      * *A/B testing*
      * *meaningful v.s. representative*
      * *representativeness and stability of results*
      * *offline v.s. online metrics*
    
    * *experiment*
    
      * *how to split trafic*
      * *how long to run*
      * *calibration*
      * *model interactions*
      * *residue effect from previous experiments*
    
    * *Productionalize/scale*
    
      * *plan for valuavle failure*
      * *measure long term/steady state effects*
      * *Engineering improvements - reuse old things*
      * *durability an robustness*
      * *measurment, monitoring, experimentation*
    
      

# Part 1

### Recommendation system overview

* > What is recommender system?

  > Application that provided to users personalized recommendations about content that they may be interested in.

* Type
  * > Content-based: analysis of the attributes of items and use simliarity between items to recommend items similar to what a user likes
  
    * creat content features for every items, but creating features is not easy
  
  * > Collaborative filtering about neighbors: use similarity between users and items simultaneously to provide recommendations, based on past user behavior (ratings, transactions)
    
    * similarities + former user behavior
    
    * need extra data - feedbacks
    
      > explicit feedback: ratings by users
      >
      > implicit feedback: infer user preference by monitering user actions like purchase, clicks
  
* elements
  * user item, context(device/location/time), interface(phone/PC..)
  
  * User, item, utility matrix(sparse)
  
    * > utility matrix: degree of preference that a user has for an item, sparse(~1%)
  
  * Architecture

#### Collabrative filtering

* memory based methods - KNN
  
  * > memory based methods: memorize the utility matrix, a type of KNN, tend to be slow
  
  * > KNN: computer distance between points, find the k nearest neighbors and vote/average
  
  * to predict whether alice is gonna like Joker
  
    * user based: find user similar to Alice and watched and rated joker
  
    * item based: find item similar to Joker that Alice wached and rated
  
    * > find movies that Alice rated that are similar to 'Joker', predict average rating on these movies for Alice's possile rating on 'Joker
  
  * measure: 
  
    * Pearson correlation
    * Cosine similarity
    * Jaccard similarity
  
* model based methods - Matrix Factorization

  * > model based methods: fit a model, tend to have better performance



# Part 2

### Matrix factorization

* > Matrix Factorization Loss function:
  > $$
  > \frac{1}{N} \sum_{(i,j): r_{ij}=1} (y_{ij}-u_iv_j)^2
  > $$

* Gradient descent with momentum

  > $$
  > w \leftarrow random \ inital \\
  > v \leftarrow 0 \\
  > Î²= 0.9 \\ 
  > \text{for i = 1: max-iter do} \\
  > v \leftarrow \beta v+(1-\beta) \triangledown E(w) \\
  > w \leftarrow w - \eta v\\
  > \text{end}
  > $$
  >
  > 

* Regularization, avoid overfitting, how to pick lambda

#### SIDE TOPIC: Feedback

- Feedback

  - explicit: Ask for rating - movies, online stores

    - User are unwilling to provide responses

    - > Implicit feedback:  biased by only from people who willing to provide ratings

  - implicit: infer user preference

    - purchase history, browsing history, search patterns

    - Pros: easy to get

    - Cons:

      - No nagative feedback, positive-only data

        - > Missing as negative: fill empty with zeros 
          >
          > * matrix is fully defined no need $(i,j): r_{ij}=1$, but can be expensice
          >
          > * may want to weight 0s less than 1s: weak negatives
          >
          > Negative sampling: sample empty spaces to get zeros
          >
          > * uniform random sampling
          > * user-oriented sampling: if a user has viewed more items, then those he/she hasn'e viewed can be sampled as negative with higher probability
          > * Item-orinted sampling: a more popular item has higher probability to be sampled as negative

      - No level of preference: how much time spent or how many times


### Content based Recommendations

* > Content based recommendation?
  >
  > Analysis of the attributes of the items, build user profiles based on the content features of the items rated by users, recommend new item based on items features and user profile
  >
  > Collaborative filtering: can be only based on user/item(KNN based), or both(MF)

- Ingredients for content based recommendation:
  - item representation: based on content
  - user representsation: based on item user liked
  - similarity metric/ machine learning model
  - ratings

#### Item profile and item-based User profile

- item profile

  - music item profile: 

    - audio content analysis
      - Features: beat..
      - high level descriptors from low-level features via Deep learning: genre, semantic
    -  text analysis: lyric, user generated context/review

  - movies item profile: actors, director, year, genre, publisher, location, image, audio

  - Document item profile: 

    - > TF-IDF: 
      > $$
      > tf(t,d) = \frac{count(t)}{|d|}\\
      > \\
      > \begin{align*}
      > df(t,N) &= \frac{|\{d_i:t \in d_i,i = 1,...,N\}|}{N}\\
      >  & \approx \frac{|\{d_i:t \in d_i,i = 1,...,N \}|+ 1}{N + 1}
      > \end{align*}
      > \\
      > \text{this is to avoid zero in side log in tfidf function}
      > $$
      >
      > $$
      > \begin{align*}
      > tfidf(t,d,N) &= \frac{tf(t,d)}{df(t,N)}\\
      >  & \approx  tf(t,d) \times log(\frac{1}{df(t,N)})
      > \end{align*}
      > $$

      - remove stopwords, compute scores, keep N words with high score as a vector for presentation 

    - Word embeddings/ sentence embedding

    - Topic modeling: the probability of a document in a topic

- User profile based on items: "user likes actor A,  director B, genre C..."

  - domographics
  - declared interests: select when creating a account
  - location/IP
  - usage features: last time visit, frequency
  - search history
  - item set: user showed interest, click, shared, liked

#### SIDE TOPIC: similarity measurement

> meansure of how similar, used in KNN

- Jaccard similarity
  $$
  \frac{|A \cap B | \leftarrow \text{intersection}}{|A\cup B| \leftarrow \text{union- - - - -}}
  $$

  * > when to use Jaccard similarity?
    >
    > * measure similarity between two sets
    >
    > * binary features, will lose information if used in non-binary features
    >   * <span style="color:#D0505D">*how to take binary features to sets?*</span>
    >   * <span style = 'color:#d0505d'>*how to go from x,y to A,B?*</span>
    > * model lack of ratings, since it only count numbers

- Cosine similarity
  $$
  \begin{align*}
  sim(x,y) = cos(\theta) &= \frac{x\cdot y}{|x|\times|y|} \\
  & = \frac{\sum_{i=1}^n x_iy_i}{\sqrt{\sum_{i=1}^{n}x_i^2}{\sqrt{\sum_{i=1}^{n}y_i^2}}}
  \end{align*}
  $$

  * > when to use cosine similarity?
    >
    > * often used in similarity between documents
    > * lack of rating is treated as 0, more similar to disliking than liking
    > * of used in positve space, $x_i, y_i \ge 0$

- Pearson coorelation coefficient
  $$
  r(x,y) = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}{\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}}
  $$

  * > when to use pearson coorelation?
    >
    > Measure of linear correaltion between two variables
    >
    > 1 is total positive correlation, 0 is no correlation, -1 is total negative correlation

### Memory based and Model based methods

* First always, compute profile vectors for users and items

#### Memory based

> K-Nearest Neighbor(KNN)
>
> * steps:
>   * pick similarity measurement and compute similarity between users and items
>   * Recommend to user items with high similarity form maybe item or other user
>
> * Scale:
>   * When too many user and items, it is too expensive to compute similarity
>     * <span style="color:#D0505D">*locality-sensitive-hashing can be used to place item profiles in buckets?*</span>
>     * <span style="color:#D0505D">given a user, easy to find buckets with high similarity to user?</span>

#### Model based

> Matrix Factorization(MF)
>
> * Train a model using the feature vectors
>   * actually likes, ratings, clicks
>   * regression to predicted ratings, classification to predict prob of click
>   * can include features that are not content based



# Part 3 Summary of recomendation system

- Summary of recommendation systems so far

  - two type
    - Content based systems: features are based on content
    - Collaborative filtering systems: behavioral data about users (rating, buying, watching) items
      - KNN (memory based)
      - Matrix factorization (model based)
      - Data: utility matrix based on explicit or implicit feedback

- >  How to make recommendations?
  >
  > - Option 1: predict rating all unseen and recommend high ratings - expensive
  > - Option 2: similay item to what she saw recently
  >   - <span style="color:#D0505D">embedding item at the very beginning as a fast approximate KNN</span>

- Pros/Cons of content base recommendation

  > - Pros 
  >   - no need for more datas on other users
  >   - no cold-start problem on new item
  >   - easy to explain: just content, and by checking the features
  > - Cons:
  >   - domain knowledge for feature vectors
  >   - new genre is hard to recognize, which is actully a unseen item feature ever
  >   - Some kind of items are not amenable to easy feature extraction (movies, music)
  >   - quality: this book are too basic, though content is ok

### SIDE TOPIC: Cold start problem

- new user with no implicite or explicite feedback
  - popular thing
  - ask for more info - tag yourself
  - social network assumption: people have similar tastes to their friends
- new item with no rating
  - content feature



# day 4

* general pytorch

  * Steps:

  * tensor(x.values)

    * unsqueese(1)

  * Detach()

    * Model(x.float())

  * Data loader:

  * generate data:

    * Class RegressionDataset()

  * Data loader

    ```python
    from torch.utils.data import Dataset, DataLoader
    train_dl = DataLoader(fake_train_ds, batch_size=1000, shuffle=True)
    valid_dl = DataLoader(fake_valid_ds, batch_size=1000, shuffle=False)
    
    x, y = next(iter(train_dl)) # next batch
    ```

  * Batching data

    * Why? data is bigger than memory; gradient noise since small set not whole

  * Shuffling data: so won't all 1 or 0

  * Load the data in parallel using multiprocessing workers.

  * loss

    ```python
    from sklearn.metrics import r2_score
    
    def val_metric(model, valid_dl):
        model.eval()
        losses = []
        y_hats = []
        ys = []
        for x, y in valid_dl:
            y = y.unsqueeze(1)
            y_hat = model(x.float()) #x.float()
            loss = F.mse_loss(y_hat, y.float())
            y_hats.append(y_hat.detach().numpy	()) # y.detach().numpy()
            ys.append(y.numpy()) 
            losses.append(loss.item()) # .item()
        
        ys = np.concatenate(ys) # extend
        y_hats = np.concatenate(y_hats)
        return np.mean(losses), r2_score(ys, y_hats)
      
    # be carefull when log loss = 0.69
    ```

  * train

    ```python
    ## train_loop function
    def train_loop(model, train_dl, valid_dl, optimizer, epochs):
        for i in range(epochs):
          	losses = []
            model.train() # be careful where the model.train() is
            for x, y in train_dl:
                y = y.unsqueeze(1)
                y_hat = model(x.float())
                loss = F.mse_loss(y_hat, y.float())
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                losses.append(loss.item())
            
            train_loss = np.mean(losses)
            valid_loss, valid_auc = val_metric(model, valid_dl)
            print("train loss %.3f valid loss %.3f auc roc %.3f" % (train_loss, valid_loss, valid_auc))
    ```

    * for each batches, the surface of bowl changes and the minimum is not a single point, it changes in each batch but in this case is more generalizable
    * Oscillating around the bottom

* Matrix factorization with PyTorch

  * Encoding data

    * 

  * Embedding layer

    * encode user and items into vectors

      ```python
      embed = nn.Embedding(10, 3)
      embed.weight # now is random
      ```

    * 'lookup' exactly from embed.weight with index

      ```python
      a = torch.LongTensor([[1,0,1,4,5,1]]) #[1,0,...] these are index inside embed.weight
      embed(a)
      ```

    * ```python
      class MF(nn.Module):
          def __init__(self, num_users, num_items, emb_size=100):
              super(MF, self).__init__()
              self.user_emb = nn.Embedding(num_users, emb_size)
              self.item_emb = nn.Embedding(num_items, emb_size)
              
              self.user_emb.weight.data.uniform_(0,0.05)
              self.item_emb.weight.data.uniform_(0,0.05) # initlializing weights
              
          def forward(self, u, v): # MF(x) called this method
              u = self.user_emb(u) # find the embedded value for user
              v = self.item_emb(v)
              return (u*v).sum(1) 
            	# element wise multiplication
           	 	# sum(1), 1 is the axis = 1
      ```

  * Debugging MF model

  * Training MF model

    ```python
    # not using data loaders because our data fits well in memory
    def train_epocs(model, epochs=10, lr=0.01, wd=0.0):
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd) 
        # wd => L2 regularization \lambda in the loss function
        # in the gradient it is (dL/du + 2Â·lambdaÂ·u)
        for i in range(epochs):
            model.train()
            users = torch.LongTensor(train.userId.values)  #.cuda()
            items = torch.LongTensor(train.movieId.values) #.cuda()
            ratings = torch.FloatTensor(train.rating.values)  #.cuda()
        
            y_hat = model(users, items)
            loss = F.mse_loss(y_hat, ratings)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            testloss = valid_loss(model)
            print("train loss %.3f valid loss %.3f" % (loss.item(), testloss)) 
    ```

    

  * MF with bias

    ```python
    class MF_bias(nn.Module):
        def __init__(self, num_users, num_items, emb_size=100):
            super(MF_bias, self).__init__()
            self.user_emb = nn.Embedding(num_users, emb_size)
            self.user_bias = nn.Embedding(num_users, 1) # bias term
            self.item_emb = nn.Embedding(num_items, emb_size)
            self.item_bias = nn.Embedding(num_items, 1)
            # init 
            self.user_emb.weight.data.uniform_(0,0.05)
            self.item_emb.weight.data.uniform_(0,0.05)
            self.user_bias.weight.data.uniform_(-0.01,0.01)
            self.item_bias.weight.data.uniform_(-0.01,0.01)
            
        def forward(self, u, v):
            U = self.user_emb(u)
            V = self.item_emb(v)
            b_u = self.user_bias(u).squeeze()
            b_v = self.item_bias(v).squeeze()
            return (U*V).sum(1) +  b_u  + b_v
    ```

  * Lab

    * Can we change the first model to predict numbers in a particular range? Hint: sigmoid would create numbers between 0 and 1. Would this improve the model? `4*sigmoid(x)+1 => [1,5]` **since it the rating thing**=> working on the loss and then changes everything
    * Would a different Loss function improve results? What about absolute value instead of F.mse_loss? `l1_loss`
      

# Part 5 Adaboost

* Kaggle competition
  * don;t use leaderboard too much may overfit
  * figure out own way to explain the problem
    * all positive, then do negative sampling
    * sea... 
  * random forest - new data, 
    * user & item vectors as some features  to random forest and see 
    * use item vectors to do random forest and see whether it works well with item_features
  * classification
  * put in some constant to check whether the data is balanced
  * it can be multiple model combined together
    * first whether gonna read or not
    * then predict the ratings
    * museum, movie, books, music, 

* Review of decision trees

  * bushy: Overfitting, high variance

  * shallow: underfitting, hight bias

  * Measure of impurity

  * Tree notation:
    $$
    T(x;\theta) = \sum_{j=1}^{J}\beta_j \mathbb{1}_{[x \in R_j]}\\
    T(x; \theta) = \frac{1}{\# items}
    $$

* Boosting question

  * Binary stump trees example, a
    $$
    T(x) = \mathbb{1}_{[x\in \{wind=false\}]} - \mathbb{1}_{[x\in \{wind=true\}]}
    $$

    * error rate is the overall error rate of the stump tree

  * weak classifiers

    * pros: fast, no-overfit
    * Cons: underfit, low accuracy
    * *how to make it better: more features, ensamble, boosting*

* Ensemble models

  * where $\alpha's$ are weights based on error rate from each binary stump, misclassified data has larger weight so it well be 'taken care' well in next tree

  $$
  G(x) = sign(\alpha_1G_1(x) + \alpha_2G_2(x)  + \alpha_3G_3(x) +...)
  $$

  * *difference between RandomForest and Adamboost?*
    * *Initially a large bias, but Adaboost has a way to change bias over time.*
    * *no way to decrease bias, all trees are deep*

* Weighted decision stumps 
  $$
  \theta^* = argmin_{\theta} \frac{\sum_{i=1}^N w_i \mathbb{1}_{[y^{(i)}\ne T(x^{(i)};\theta]}}{\sum_{i=1}^{N}w_i}\\
  
  w_i = w_i \cdot exp[\alpha_m \cdot \mathbb{1}_{[y^{(i)}\ne T(x^{(i)}]}]\\ 
  \text{where }\alpha_m = log(\frac{1-err_m}{err_m}) \text{, lower error, higher weight}
  $$

  * *the weights are only used for classification error in training* 

    * *round1: pick the lowerest error tree and update the mis-classified item rate, if the err is $< 0.5$, then $w_i$ will increase and we will never get an error rate $>0.5$,*
      $$
      w_i = w_i \times log(\frac{1-err}{err})
      $$

    * *round 2: pick the lowest error rate tree and update $w_i$ again*
    * final vote with all trees, thought each based on former

  * strategy is to just misclassify those has lower weights and make right those larger weight

* Lab: start working on the Kaggle competition







