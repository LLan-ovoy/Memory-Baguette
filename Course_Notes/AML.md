# Introduction

* Trends in ML: 

  * Deep Learning
    * text generation
    * Translation
    * Picture/music recognition

  * Natural Language Processing

    * BERT
    * unsupervised pretrainnng:
      * training models on tasks generated by natural text
      * with it can traning models with fewer labelled examples.
    * When using, need to easily finetune a little

  * > What is Transfer Learning?

    > Improvement of learning on a new task by trasfering the knowledge from a related task that have already been learned

    * recycling
    * good for image and NLP

  * Appiled ML:

    * Deep nerual nets:
      * convolutional nets for image
      * RNNs, BERT/Transformer for NLP
    * ensembled model add 2-5% in performance, but also rather comlex and not worth it in practice.

* ML in industry
  * feature engineering
  
  * recommender system
  
  * ***Models, but not just building mdels - selecting and framing a problem***
    
    * *start with a business problem*
    
      * *establish a baseline*
      * *check your assumption*
      * *Select model/learning technique*
      * *Select feature*
      * *Measure/evaluate, experiment*
      * *stability scalability robustness*
    
    * *break down the problem*
    
    * *understand the impact*
    
    * *Find the right data*
    
    * *select an objective function*
    
    * *build models*
    
    * *measure and evaluate*
    
      * *definiting the right metrics*
      * *offline evaluation*
      * *A/B testing*
      * *meaningful v.s. representative*
      * *representativeness and stability of results*
      * *offline v.s. online metrics*
    
    * *experiment*
    
      * *how to split trafic*
      * *how long to run*
      * *calibration*
      * *model interactions*
      * *residue effect from previous experiments*
    
    * *Productionalize/scale*
    
      * *plan for valuavle failure*
      * *measure long term/steady state effects*
      * *Engineering improvements - reuse old things*
      * *durability an robustness*
      * *measurment, monitoring, experimentation*
    
      

# Part 1

### Recommendation system overview

* > What is recommender system?

  > Application that provided to users personalized recommendations about content that they may be interested in.

* Type
  * > Content-based: analysis of the attributes of items and use simliarity between items to recommend items similar to what a user likes
  
    * creat content features for every items, but creating features is not easy
  
  * > Collaborative filtering about neighbors: use similarity between users and items simultaneously to provide recommendations, based on past user behavior (ratings, transactions)
    
    * similarities + former user behavior
    
    * need extra data - feedbacks
    
      > explicit feedback: ratings by users
      >
      > implicit feedback: infer user preference by monitering user actions like purchase, clicks
  
* elements
  * user item, context(device/location/time), interface(phone/PC..)
  
  * User, item, utility matrix(sparse)
  
    * > utility matrix: degree of preference that a user has for an item, sparse(~1%)
  
  * Architecture

#### Collabrative filtering

* memory based methods - KNN
  
  * > memory based methods: memorize the utility matrix, a type of KNN, tend to be slow
  
  * > KNN: computer distance between points, find the k nearest neighbors and vote/average
  
  * to predict whether alice is gonna like Joker
  
    * user based: find user similar to Alice and watched and rated joker
  
    * item based: find item similar to Joker that Alice wached and rated
  
    * > find movies that Alice rated that are similar to 'Joker', predict average rating on these movies for Alice's possile rating on 'Joker
  
  * measure: 
  
    * Pearson correlation
    * Cosine similarity
    * Jaccard similarity
  
* model based methods - Matrix Factorization

  * > model based methods: fit a model, tend to have better performance



# Part 2

### Matrix factorization

* > Matrix Factorization Loss function:
  > $$
  > \frac{1}{N} \sum_{(i,j): r_{ij}=1} (y_{ij}-u_iv_j)^2
  > $$

* Gradient descent of MF

  > $$
  > Loss = E(U,V) = \frac{1}{N}\sum_{(i,j):r_{i,j}=1} (y_{ij}-u_iv_j)^2 \\
  > 
  > \frac{\partial L}{\partial u_{ik}} = -\frac{2}{N} \sum_{j:r_{i,j}=1} (y_{ij}-u_iv_j) v_{jk} \\
  > 
  > \frac{\partial L}{\partial v_{jk}} = -\frac{2}{N} \sum_{i:r_{i,j}=1} (y_{ij}-u_iv_j) u_{ik} \\
  > 
  > u_{ik} \leftarrow u_{ik} + \frac{2\eta}{N} \sum_{j:r_{i,j}=1} (y_{ij}-u_iv_j) v_{jk} \\
  > 
  > v_{jk} \leftarrow v_{jk} + \frac{2\eta}{N} \sum_{i:r_{i,j}=1} (y_{ij}-u_iv_j) u_{ik}
  > $$
  >
  > Vectorized
  > $$
  > \Delta = (Y - U\cdot V^T)\\
  > 
  > \frac{\partial E}{\partial U} = -\frac{2}{N} \Delta \cdot V\\
  > 
  > \frac{\partial E}{\partial V} = -\frac{2}{N} \Delta^T \cdot U
  > $$
  > 

* Gradient descent with momentum

  > $$
  > w \leftarrow random \ inital \\
  > v \leftarrow 0 \\
  > β= 0.9 \\
  > \\
  > 
  > v_t \leftarrow \beta v_{t-1} + (1-\beta) \triangledown E(w_t) \\
  > w_{t+1} \leftarrow w_t - \eta v_t\\
  > $$
  > 

  

* Regularization, avoid overfitting, how to pick lambda

  > $$
  > \frac{1}{N}\sum_{(i,j):r_{ij}=1}(y_{ij}-u_iv_j)^2 + \lambda(\sum_{i=1}^{n_u}\sum_{k=1}^{K} u_{ik}^2 + \sum_{i=1}^{n_m}\sum_{k=1}^{K} v_{ik}^2)\\
  > 
  > \text{where,} N =\sum_{ij}r_{ij}
  > $$

#### SIDE TOPIC: Feedback

- Feedback

  - explicit: Ask for rating - movies, online stores

    - User are unwilling to provide responses

    - > Implicit feedback:  biased by only from people who willing to provide ratings

  - implicit: infer user preference

    - purchase history, browsing history, search patterns

    - Pros: easy to get

    - Cons:

      - No nagative feedback, positive-only data: only know user listen to which song, but don't know which song user hate

        - > Missing as negative: fill empty with zeros 
          >
          > * matrix is fully defined no need $(i,j): r_{ij}=1$, but can be expensice
          >
          > * may want to weight 0s less than 1s: weak negatives
          >
          > Negative sampling: sample empty spaces to get zeros
          >
          > * uniform random sampling
          > * user-oriented sampling: if a user has viewed more items, then those he/she hasn'e viewed can be sampled as negative with higher probability
          > * Item-orinted sampling: a more popular item has higher probability to be sampled as negative

      - No level of preference: how much time spent or how many times


### Content based Recommendations

* > Content based recommendation?
  >
  > Analysis of the attributes of the items, build user profiles based on the content features of the items rated by users, recommend new item based on items features and user profile
  >
  > Collaborative filtering: can be only based on user/item(KNN based), or both(MF)

- Ingredients for content based recommendation:
  - item representation: based on content
  - user representsation: based on item user liked
  - similarity metric/ machine learning model
  - ratings

#### Item profile and item-based User profile

- item profile

  - music item profile: 

    - audio content analysis
      - Features: beat..
      - high level descriptors from low-level features via Deep learning: genre, semantic
    -  text analysis: lyric, user generated context/review

  - movies item profile: actors, director, year, genre, publisher, location, image, audio

  - Document item profile: 

    - > TF-IDF: 
      > $$
      > tf(t,d) = \frac{count(t)}{|d|}\\
      > \\
      > \begin{align*}
      > df(t,N) &= \frac{|\{d_i:t \in d_i,i = 1,...,N\}|}{N}\\
      >  & \approx \frac{|\{d_i:t \in d_i,i = 1,...,N \}|+ 1}{N + 1}
      > \end{align*}
      > \\
      > \text{this is to avoid zero in side log in tfidf function}
      > $$
      >
      > $$
      > \begin{align*}
      > tfidf(t,d,N) &= \frac{tf(t,d)}{df(t,N)}\\
      >  & \approx  tf(t,d) \times log(\frac{1}{df(t,N)})
      > \end{align*}
      > $$

      - remove stopwords, compute scores, keep N words with high score as a vector for presentation 

    - Word embeddings/ sentence embedding

    - Topic modeling: the probability of a document in a topic

- User profile based on items: "user likes actor A,  director B, genre C..."

  - domographics
  - declared interests: select when creating a account
  - location/IP
  - usage features: last time visit, frequency
  - search history
  - item set: user showed interest, click, shared, liked

#### SIDE TOPIC: similarity measurement

> meansure of how similar, used in KNN

- Jaccard similarity
  $$
  \frac{|A \cap B | \leftarrow \text{intersection}}{|A\cup B| \leftarrow \text{union- - - - -}}
  $$

  * > when to use Jaccard similarity?
    >
    > * measure similarity between two sets
    >
    > * binary features, will lose information if used in non-binary features
    >   * <span style="color:#D0505D">*how to take binary features to sets?*</span> *=> general cases*
    >   * <span style = 'color:#d0505d'>*how to go from x,y to A,B?*</span> 
    > * model lack of ratings, since it only count numbers

- Cosine similarity
  $$
  \begin{align*}
  sim(x,y) = cos(\theta) &= \frac{x\cdot y}{|x|\times|y|} \\
  & = \frac{\sum_{i=1}^n x_iy_i}{\sqrt{\sum_{i=1}^{n}x_i^2}{\sqrt{\sum_{i=1}^{n}y_i^2}}}
  \end{align*}
  $$

  * > when to use cosine similarity?
    >
    > * often used in similarity between documents
    > * lack of rating is treated as 0, more similar to disliking than liking
    > * of used in positve space, $x_i, y_i \ge 0$

- Pearson coorelation coefficient
  $$
  r(x,y) = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2}{\sqrt{\sum_{i=1}^{n}(y_i - \bar{y})^2}}}
  $$

  * > when to use pearson coorelation?
    >
    > Measure of linear correaltion between two variables
    >
    > 1 is total positive correlation, 0 is no correlation, -1 is total negative correlation

### Memory based and Model based methods

* First always, compute profile vectors for users and items

#### Memory based

> K-Nearest Neighbor(KNN)
>
> * steps:
>   * pick similarity measurement and compute similarity between users and items
>   * Recommend to user items with high similarity form maybe item or other user
>
> * Scale:
>   * When too many user and items, it is too expensive to compute similarity
>     * <span style="color:#D0505D">*locality-sensitive-hashing can be used to place item profiles in buckets?*</span>
>     * <span style="color:#D0505D">given a user, easy to find buckets with high similarity to user?</span>

#### Model based

> Matrix Factorization(MF)
>
> * Train a model using the feature vectors
>   * actually likes, ratings, clicks
>   * regression to predicted ratings, classification to predict prob of click
>   * can include features that are not content based



# Part 3 Summary of recomendation system

- Summary of recommendation systems so far

  - two type
    - Content based systems: features are based on content
    - Collaborative filtering systems: behavioral data about users (rating, buying, watching) items
      - KNN (memory based)
      - Matrix factorization (model based)
      - Data: utility matrix based on explicit or implicit feedback

- >  How to make recommendations?
  >
  > - Option 1: predict rating all unseen and recommend high ratings - expensive
  > - Option 2: similay item to what she saw recently
  >   - <span style="color:#D0505D">embedding item at the very beginning as a fast approximate KNN</span>

- Pros/Cons of content base recommendation

  > - Pros 
  >   - no need for more datas on other users
  >   - no cold-start problem on new item
  >   - easy to explain: just content, and by checking the features
  > - Cons:
  >   - domain knowledge for feature vectors
  >   - new genre is hard to recognize, which is actully a unseen item feature ever
  >   - Some kind of items are not amenable to easy feature extraction (movies, music)
  >   - quality: this book are too basic, though content is ok

### SIDE TOPIC: Cold start problem

- new user with no implicite or explicite feedback
  - popular thing
  - ask for more info - tag yourself
  - social network assumption: people have similar tastes to their friends
- new item with no rating
  - content feature



# Part 4 Pytorch

### general pytorch

* **transfer data to tensor**

  * ```python
    x = torch.tensor([[1,2],[3,4]])
    x.shape #2,2
    
    x = torch.randn(5,10).type(torch.FloatTensor)
    x.shape #5,10
    x.view(1,-1).shape # 1,50
    ```

  * unsqueese(1)

    ```
    x.unsqueeze(2)
    x.shape #5,10,1
    ```

* **autograd flag**

  * ```python
    # a signal telling pytorch it is going to do gradient descent on this variable
    x = torch.tensor([1,2,3,4,5,6], requires_grad=True)
    x = torch.tensor([1,2,3,4,5,6]).requires_grad_()
    ```

  * How it works

    ```python
    L = (2*x**2 + 1).mean()
    L.backward()
    x.grad #tensor([0.6667, 1.3333, 2.0000, 2.6667, 3.3333, 4.0000]
    ```

  * How to remove it? This is useful at validation time

    ```python
    torch.no_grad()
    # Prevent the gradients from being calculated in a piece of code. This is useful at validation time
    ```

* **Detach to numpy**

  ```python
  x.detach().numpy()
  ```

### Create Model

`nn.Linear(5, 3)` creates a linear transformation with parameters $A$ and $b$ ($A\cdot X+b$). Given an input matrix of observations $X$ ($N \times 5$), `nn.Linear(5, 3)` transforms X into a $N \times 3$ matrix, where $N$ can be anything (number of observations).

```python
def lin(a,x,b): return a*x+b

def gen_fake_data(n,a,b):
  x = np.random.uniform(0,1,n)
  y = lin(a,x,b) + 0.1* np.random.normal(0,3,n)
  return x,y

x,y = gen_fake_data(50,3,8)

def mse(y_hat, y):
  return np.mean((y-y_hat)**2)

def mse_loss(a, b, x, y): 
  return mse(lin(a,b,x), y)
```

* **Model in pytorch**

  ```python
  model = torch.nn.Sequential(
  	nn.Linear(1,1)
  )
  model
  ```

  * write it in a class

  ```python
  class LinearRegression(nn.Module):
  		def __init__(self):
      		super(LinearRegression, self).__init__()
          self.lin = nn.Linear(1,1)
          
      def forward(self, x): ## create a model by calling LinearRegression()   
        	x = self.lin(x)
          return x
        
  model = LinearRegression()  
  model(x.float())
  ```

  * data dimension opeartion

  ```python
  x, y = gen_fake_data(10000, 3., 8.)
  x = torch.tensor(x).float()
  y = torch.tensor(y).float()
  x.shape #10000
  
  x_2 = torch.unsqueeze(x, 1)
  x_2.shape # 10000,1
  
  x_3 = torch.squeeze(x, 1)
  x_3.shape # 10000
  ```

* **Optimizer**

  * ```python
    learning_rate = 0.1
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    ```

### A general process

* elements:

  * ```model.train()```
  * Calculate `y_hat = model(x)`
  * specify `loss = F.mse_loss(y_hat, y)`
  * `optimizer.zero_grad()`
  * `loss.backward()`
  * `optimizer.step()`
  * `model.eval()`, this is for validation

  ```python
  for t in range(1000):
    	model.train() 							# turn on training mode
      y_hat = model(x.float()) 						# apply model on x to compute y_hat
      loss = F.mse_loss(y_hat, y) # calculate loss
      # loss = F.binary_cross_entropy_with_logits(y_hat, y)
      
      optimizer.zero_grad()				# set optimizer's variables's grad to be 0
      loss.backward()							# compute gradient
      # Computes the gradient of loss with respect to all Variables with requires_grad=True.
      # After this call a.grad and b.grad will be Variables holding the gradient
      # of the loss with respect to a and b respectively
      
      optimizer.step()						# update optimizer's parameters
      
      model.eval()								# turn on evaluate mode
      y_hat_val = model(x_val)
      val_loss = F.mse_loss(y_hat_val, y_val)
      # val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)
      print(loss.item(), val_loss.item())
  ```

### Integrate Data

```python
from torch.utils.data import Dataset, DataLoader
```

* generate dataset

  ```python
  def lin(a,b,x): return a*x+b
  
  def gen_fake_data(n, a, b):
      x = np.random.uniform(0,1,n) 
      y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)
      return x.astype(np.float32), y.astype(np.float32)
  
  # create a dataset
  class RegressionDataset(Dataset):
      def __init__(self, a=3, b=8, n=10000):
          x, y = gen_fake_data(n, a, b)
          x = torch.from_numpy(x).unsqueeze(1)
          y = torch.from_numpy(y)
          self.x, self.y = x, y
      
      def __len__(self):
          return len(self.y)
      
      def __getitem__(self, idx):
          return self.x[idx], self.y[idx]
      
  fake_train_ds = RegressionDataset()
  fake_valid_ds = RegressionDataset()
  ```

* Data loader

  ```python
  train_dl = DataLoader(fake_train_ds, batch_size=1000, shuffle=True)
  valid_dl = DataLoader(fake_valid_ds, batch_size=1000, shuffle=False)
  
  x, y = next(iter(train_dl)) # next batch
  ```

  * what is data loader used for?
    * Batching data
      * Why? data is bigger than memory; gradient noise since small set not whole
      * for each batches, the surface of bowl changes and the minimum is not a single point, it changes in each batch but in this case is more generalizable
    * Shuffling data: so won't all 1 or 0
      * no need to shuffle validation data since it is not used for training
    * Load the data in parallel using multiprocessing workers.

* loss

  ```python
  from sklearn.metrics import r2_score
  
  def val_metric(model, valid_dl):
      model.eval()
      losses = []
      y_hats = []
      ys = []
      for x, y in valid_dl:
          y = y.unsqueeze(1)
          y_hat = model(x.float()) #x.float()
          loss = F.mse_loss(y_hat, y.float())
          y_hats.append(y_hat.detach().numpy	()) # y.detach().numpy()
          ys.append(y.numpy()) 
          losses.append(loss.item()) # .item()
      
      ys = np.concatenate(ys) # extend
      y_hats = np.concatenate(y_hats)
      return np.mean(losses), r2_score(ys, y_hats)
    
  # be carefull when log loss = 0.69
  ```

* train

  ```python
  ## train_loop function
  def train_loop(model, train_dl, valid_dl, optimizer, epochs):
      for i in range(epochs):
        	losses = []
          model.train() # be careful where the model.train() is
          for x, y in train_dl:
              y = y.unsqueeze(1)
              y_hat = model(x.float())
              loss = F.mse_loss(y_hat, y.float())
              optimizer.zero_grad()
              loss.backward()
              optimizer.step()
              losses.append(loss.item())
          
          train_loss = np.mean(losses)
          valid_loss, valid_auc = val_metric(model, valid_dl)
          print("train loss %.3f valid loss %.3f auc roc %.3f" % (train_loss, valid_loss, valid_auc))
  ```


* Matrix factorization with PyTorch

  * Encoding data: remove validation data which not in training data

    ```python
    userid2idx = {o:i for i,o in enumerate(train_user_ids)}
    
    train["userId"] = train["userId"].apply(lambda x: userid2idx[x])
    val["userId"] = val["userId"].apply(lambda x: userid2idx.get(x, -1)) 
    # -1 for users not in training
    ```

  * Embedding layer

    * encode user and items into vectors

      ```python
      embed = nn.Embedding(10, 3)
      embed.weight # now is random
      ```

    * 'lookup' exactly from embed.weight with index

      ```python
      a = torch.LongTensor([[1,0,1,4,5,1]]) #[1,0,...] these are index inside embed.weight
      embed(a)
      ```

    * ```python
      class MF(nn.Module):
          def __init__(self, num_users, num_items, emb_size=100):
              super(MF, self).__init__()
              self.user_emb = nn.Embedding(num_users, emb_size)
              self.item_emb = nn.Embedding(num_items, emb_size)
              
              self.user_emb.weight.data.uniform_(0,0.05)
              self.item_emb.weight.data.uniform_(0,0.05) # initlializing weights
              
          def forward(self, u, v): # MF(x) called this method
              u = self.user_emb(u) # find the embedded value for user
              v = self.item_emb(v)
              return (u*v).sum(1) 
            	# element wise multiplication
           	 	# sum(1), 1 is the axis = 1
      ```

  * Training MF model

    ```python
    # not using data loaders because our data fits well in memory
    def train_epocs(model, epochs=10, lr=0.01, wd=0.0):
        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd) 
        # wd => L2 regularization \lambda in the loss function
        # in the gradient it is (dL/du + 2·lambda·u)
        for i in range(epochs):
            model.train()
            users = torch.LongTensor(train.userId.values)  #.cuda()
            items = torch.LongTensor(train.movieId.values) #.cuda()
            ratings = torch.FloatTensor(train.rating.values)  #.cuda()
        
            y_hat = model(users, items)
            loss = F.mse_loss(y_hat, ratings)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            testloss = valid_loss(model)
            print("train loss %.3f valid loss %.3f" % (loss.item(), testloss)) 
    ```

    ```python
    def valid_loss(model):
        model.eval()
        users = torch.LongTensor(val.userId.values) 
        items = torch.LongTensor(val.movieId.values) 
        ratings = torch.FloatTensor(val.rating.values) 
        y_hat = model(users, items)
        loss = F.mse_loss(y_hat, ratings)
        abs_loss = F.L1_loss(y_hat, ratings)
        return loss.item(), abs_loss.item()
    ```

  * MF with bias

    ```python
    class MF_bias(nn.Module):
        def __init__(self, num_users, num_items, emb_size=100):
            super(MF_bias, self).__init__()
            self.user_emb = nn.Embedding(num_users, emb_size)
            self.user_bias = nn.Embedding(num_users, 1) # bias term
            self.item_emb = nn.Embedding(num_items, emb_size)
            self.item_bias = nn.Embedding(num_items, 1)
            # init 
            self.user_emb.weight.data.uniform_(0,0.05)
            self.item_emb.weight.data.uniform_(0,0.05)
            self.user_bias.weight.data.uniform_(-0.01,0.01)
            self.item_bias.weight.data.uniform_(-0.01,0.01)
            
        def forward(self, u, v):
            U = self.user_emb(u)
            V = self.item_emb(v)
            b_u = self.user_bias(u).squeeze()
            b_v = self.item_bias(v).squeeze()
            return (U*V).sum(1) +  b_u  + b_v
    ```

  * Lab

    * Can we change the first model to predict numbers in a particular range? Hint: sigmoid would create numbers between 0 and 1. Would this improve the model? `4*sigmoid(x)+1 => [1,5]` **since it the rating thing**=> working on the loss and then changes everything
    * Would a different Loss function improve results? What about absolute value instead of F.mse_loss? `l1_loss`











# Part 5 Adaboost

* **Kaggle competition**
  
  * **don;t use leaderboard too much may overfit**
  * **figure out own way to explain the problem**
    * **all positive, then do negative sampling**
    * **sea...** 
  * **random forest - new data,** 
    * **user & item vectors as some features  to random forest and see** 
    * **use item vectors to do random forest and see whether it works well with item_features**
  * **classification**
  * **put in some constant to check whether the data is balanced**
  * **it can be multiple model combined together**
    * **first whether gonna read or not**
    * **then predict the ratings**
    * **museum, movie, books, music,** 
  * **get a mean user**
    * **do average on embeddings**
    * **compute a mean user by randomly asign labels to a user, like create a new user as u_n+1**
  
* Review of decision trees

  * bushy: Overfitting, high variance

  * shallow: underfitting, hight bias

  * Measure of impurity

  * Tree notation:
    $$
    T(x;\theta) = \sum_{j=1}^{J}\beta_j \mathbb{1}_{[x \in R_j]}\\
    T(x; \theta) = \frac{1}{\# items}
    $$

* Boosting question

  * Binary stump trees example, a
    $$
    T(x) = \mathbb{1}_{[x\in \{wind=false\}]} - \mathbb{1}_{[x\in \{wind=true\}]}
    $$

    * error rate is the overall error rate of the stump tree

  * weak classifiers

    * pros: fast, no-overfit
    * Cons: underfit, low accuracy
    * *how to make it better: more features, ensamble, boosting*

* Ensemble models

  * where $\alpha's$ are weights based on error rate from each binary stump, misclassified data has larger weight so it well be 'taken care' well in next tree

  $$
  G(x) = sign(\alpha_1G_1(x) + \alpha_2G_2(x)  + \alpha_3G_3(x) +...)
  $$

  * *difference between RandomForest and Adamboost?*
    * *Initially a large bias, but Adaboost has a way to change bias over time.*
    * *no way to decrease bias, all trees are deep*

* Weighted decision stumps 
  $$
  \theta^* = argmin_{\theta} \frac{\sum_{i=1}^N w_i \mathbb{1}_{[y^{(i)}\ne T(x^{(i)};\theta]}}{\sum_{i=1}^{N}w_i}\\
  
  w_i = w_i \cdot exp[\alpha_m \cdot \mathbb{1}_{[y^{(i)}\ne T(x^{(i)}]}]\\ 
  \text{where }\alpha_m = log(\frac{1-err_m}{err_m}) \text{, lower error, higher weight}
  $$

  * *the weights are only used for classification error in training* 

    * *round1: pick the lowerest error tree and update the mis-classified item rate, if the err is $< 0.5$, then $w_i$ will increase and we will never get an error rate $>0.5$,*
      $$
      w_i = w_i \times log(\frac{1-err}{err})
      $$

    * *round 2: pick the lowest error rate tree and update $w_i$ again*
    * final vote with all trees, thought each based on former

  * strategy is to just misclassify those has lower weights and make right those larger weight

* Lab: start working on the Kaggle competition



# Part 6 Gradient Boosting

- review of Adaboost

  - stump tree with only one feature,  pick the lowest error rate
  - Weight observations of misclassified with this error rate log(/)
  - Redo pick loest error rate with weight
  - in random forest, tree are same, sometime forget a feature

- additive modelingintuition

  - in adaboost, average classifiers

  $$
  F(x) = sign(f(x)) = sign(\sum_{m=1}^{M}\alpha_m T_m(x))
  $$

  * each feature was take cared by a function, still a sum, kind of same as adaboost, but adaboost can use same features for several times

  $$
  \hat{y} = b+g_1(x_1)+g_2(x_2)...
  $$

  - Intuition: decomposing a simple terms, it may not be good

- gradient boosting

  - $$
    \hat{y} = \bar{y} + T_1(x) + T_2(x) + ...
    $$

  - *random forest, always fit on the same data, worry about overfit, gradient boosting use different?*

- Gradient boosting for Regression with MSE

  - steps:

    ![gradientboost](image/msegb.png)

    - Round1
      - take **mean** of y: minimize the MSE
    - Round 2
      - find best split, x = x, y = SE = (y_real - y_pred1)
        - compute the MSE the two side of a split
      - random split x, and  predcit 

- Gradient boosting for Regression with MAE

  ![msebg](image/maegb.png)

  - Round1

    - take **median** of y: minimize the MSE

  - Round 2

    - find best split of x = x, **y = sign(SE), this is a classification**:
      - compute the MSE the two side of a split

    - random split x, and  predcit 

- What all these algorithms have in common?

- Gradient boosting

  - Regularization for boosting: learning rate
    $$
    f_m(x) = f_{m-1}(x) + vT(x;\theta_m)
    $$

* algorithm
  $$
  f_0(x) = argmin_\beta \sum \\
  
  r_i = -[\frac{\partial L(y,f)}{\partial f}]\\
  
  \begin{align*}
  r_i &= -\frac{\partial L}{\partial f}|_{f=f_{m-1}(x^{(i)}), y = y^{(i)}} \\
  & = y^{(i)}-f_{m-1}(x^{(i)})\\
  \end{align*}
  $$

  $$
  \begin{align*}
  \beta &= argmin_{\beta} \sum_{x^{(i)} \in R} L(y^{(i)}, f_{m-1}(x^{(i)}+\beta))\\
  &= \sum_{}
  \end{align*}
  $$

  
